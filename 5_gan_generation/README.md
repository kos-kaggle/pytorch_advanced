# 5 GANによる画像生成（DCGAN, Self-Attention GAN）
参考サイト：
- 深層生成モデルを巡る旅(3): GAN  
https://qiita.com/shionhonda/items/330c9fdf78e62db3402b
- GANのなめらかさと安定性  
https://tech.preferred.jp/ja/blog/smoothness-and-stability-in-gans/
- 固有値・固有ベクトル  
https://www.geisya.or.jp/~mwm48961/linear_algebra/eigenvalue2.htm  
- リプシッツ連続性  
https://mathwords.net/lipschitz

## 5-1 GANによる画像生成のメカニズムとDCGANの実装
- ２種類のネットワークを用意
    - 画像を生成するGenerator（以下、G）。訓練データに近い画像を生成できるよう学習。
    - 画像がGから生成された偽画像か、訓練データで用意した画像かを分類するDiscriminator（以下、D）。真贋を見分けられるよう学習。
- GはDを騙そうと、DはGに騙されないようにと、互いに学習を進めることでリアルな画像を生成できるようになる。これを実装のイメージまで持っていくのが本章の目的。

1. Generatorが画像を生成するためにどのようなニューラルネットワークの構造になっているのかを理解する
    - 乱数を入力して様々なパターンの画像を生成するネットワーク
    - nn.ConvTranspose2d()という層で、入力乱数の次元と要素数を拡大して画像化する
        - 転置畳み込み(transposed convolution / Deconvolution)：通常の畳み込みと違い、入力データの１セルごとにカーネルを掛け算して足し合わせる。繰り返すことで特徴量マップの要素数が大きくなる（図5.1.2）。
    - 学習の初期段階では全く訓練データと似ていない画像が出力される。そのため、完璧な教師データを使うと全て偽画像と判定され、学習が進まない。
    -> そこで完璧な教師データの代わりに、同じく学習初期段階のDiscriminatorを使う。

2. Discriminatorが画像の識別をするためにどのようなニューラルネットワークの構造になっているのかを理解する
    - 単なる画像分類のネットワーク（教師データで用意した画像か偽画像かを判定する）
    - 初期段階では未学習のネットワークのため、Gの生成画像を訓練データと誤分類する場合がある。
    -> Dの甘い判定から、Gは学習を進めやすくなる。相互に騙し騙されながら学習を進めていくため、Adversarial(敵対)という名前がつく。
    - GANのDでは、Conv層にReLUではなくLeakyReLU（入力値が負のとき、入力値×係数を出力）を使う。
        - Gの損失計算にDの判定結果が入る（5.2節参照）ため、バックプロパゲーションがD->Gの順番に伝播する。そのためDにReLUを使うと、出力が0の場合は上位層であるGまで勾配計算が伝わらない。LeakyReLUの場合は出力0とならないため、ネットワークが学習しやすくなる。

3. GANの一般的な損失関数の形とニューラルネットワークの学習の流れを理解する
-> 5.2節

4. DCGAN(Deep Convolution Generative Adversarial Network)のネットワークを実装できるようになる
    - Gでは入力に近い層ほど転置畳み込みのチャネル数を多くする
    - Dでは出力に近い層ほど畳み込みのチャネル数を多くする


## 5-2 DCGANの損失関数、学習、生成の実装
1. GANの損失関数の形を理解する
    - Discriminatorの損失関数：
        - バイナリクロスエントロピーを最小化。pytorchではtorch.nn.BCEWithLogitsLoss()を利用する。
    - Generatorの損失関数：
        - Dを騙したいので、Dの損失関数を逆に最大化させる。
        - そのままの式だとDに見抜かれた時に損失が０になってしまうので、Dに見抜かれたら損失が大きくなるよう式を変形（初期Gの生成画像は初期Dでも見抜かれやすいため）。
        - Dの時と同様にBCEWithLogitsLoss()を利用できる。（ただしDの損失を最大化させることを表現するために、正解ラベルは真逆のものを引数として渡す。）

2. DCGANを実装し、手書き数字画像が生成できる
    1. DataLoaderの作成（これまでの章と同じだが、Datasetは学習と検証で分けない）
    2. DCGANの学習
        - 重みは正規分布に従って初期化（DCGANでは経験的に上手くいくらしい）
        - optimizerをGとDそれぞれに設定（実装例ではどちらもAdam）
        - 誤差関数を定義（バイナリクロスエントロピー）
        - データローダーからミニバッチ分の教師データ（手書き数字画像・真の画像）を取り出し、以下を繰り返す
            1. Discriminatorの学習：
                1. Dに真の画像を入力して真贋判定
                2. Gに乱数を入力して偽の画像を生成し、それをDに入力して真贋判定
                3. 1,2の判定をもとに、Dの損失を計算してDの重みを更新
            2. Generatorの学習：
                1. Gに乱数を入力して偽の画像を生成し、それをDに入力して真贋判定
                2. 1の判定をもとに、Gの損失を計算してGの重みを更新

## 5-3 Self-Attention GAN （SANGAN） の概要
- DCGANの発展版で、元々Transformerなどで使われていたSelf-Attentionを用いた手法。Ian Goodfellowらが2018年に提唱。

1. Self-Attentionを理解する
    - 転置畳み込み（畳み込み）の問題点：局所的な情報の拡大（集約）であって、画像全体の大域的な情報を考慮していない -> 大域的に見て似ている箇所に着目したい
    - Self-Attention：自分自身（対象セル）と似ているデータに着目すること
        - あるlayerへの入力 x（テンソルサイズ：クラス数C × 高さH × 幅W）を、大域的な情報を考慮して y=x+γo と調整する（γ：係数、o：Self-Attention Map）
        - Self-Attention Mapの計算（図5.3.2参照）：
        xをC×Nの二次元(N=H×W)に変形し、転置xとxをかけた行列Sを計算する。Sの要素i,jの値は、画像位置iと画像位置jがどれくらい似ているかを表す度合いとなる。これを正規化したものをxにかけた行列oがSelf-Attention Map（size:C×N）
    - Self-Attentionの補足：
        - 通常の畳み込み：計算コストのため小さいカーネルを利用 -> 対象セルの周囲のセルのみに着目するため局所的
        - Self-Attention：対象セルの特徴量を計算するのに自身と値が似ているセルに着目 -> 大域的かつ計算コストを抑えている

2. 1×1 Convolutions (pointwise convolution) の意味を理解する
    - Self-Attentionをそのまま入力データxにかけても性能は上がりにくい -> 入力データxを先に特徴量変換する
    - pointwise convolution（図5.3.3参照）:
        - カーネルサイズ1×1の畳み込み層でxのチャネル数を圧縮させる。
        - 1×1をチャネル方向に畳み込むので、要はチャネルごとの線形和。異なるカーネルを複数個用意すれば、異なる係数でチャネルごとに線形和をとったものが複数個出力される。
        - カーネルの重みを学習することで、入力xの情報を欠落させず次元圧縮でき、計算コストを下げられる。

3. Spectral Normalizationの気持ちを理解する
    - 畳み込み層などのネットワークの重みパラメータを正規化
    - GANではDがリプシッツ連続性（=入力が少し変化しても出力がほとんど変化しないこと）を有する必要がある
    - 入力画像の小さな変化が出力で拡大されることを防ぐために、最大固有値でパラメータを割り算して規格化する
    - SAGANではDだけでなく生成器Gの畳み込み層にもSpectral Normalizationを利用する


## 5-4 Self Attention GANの学習、生成の実装
1. SAGANを実装できるようになる
    - ベースはDCGANで、畳み込み層にSpectral Normalization、layer間にSelf-Attentionモジュールを追加する
    - SAGANの識別器Dの損失関数はhinge version of the adversarial lossを使用 -> 論文著者曰く、経験的にうまくいく