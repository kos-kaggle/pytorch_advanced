## 4.1 姿勢推定とOpenPoseの概要

- 姿勢推定とは、何をインプットに何をアウトプットする手法なのか理解する
    - 画像→複数人物検出
    - →各人物の部位検出 (18)
    - →部位をつなぐ線(リンク, 37)を求める
- MS COCO Keypointsデータを理解する
    - MS COCO : 画像を使用したDLタスク全般の汎用データセット
        - 想定タスク：画像分類、物体検出、セマンティックセグメンテーション、姿勢推定、キャプション生成
    - Keypoints : 姿勢推定用のデータセット
        - ファイル形式：json
        - 複数人物の表現：json_self, json_others
        - 訓練/検証の分割：datasetキー(COCO, COCO_val)またはisValidationキー
        - 画像データのリンク：img_pathsキー
        - メイン人物の部位アノテーション数：num_keypoints(最大17, 首なし)
        - メイン人物のバウンディングボックス情報：scale_providedキー、368pixelの何倍か
        - 部位の座標、視認性情報：joint_self, joint_othersキー(x, y, 視認性情報)
            - 視認性情報：0 - 座標あり、部位映像なし、1 - 座標、部位映像あり、2 - 座標、部位映像なし
- 姿勢推定タスクの概要
    - 部位の特定 - セマンティックセグメンテーション
        - ピクセルごとに、クラス分類(3章)ではなく、確率を回帰する(18部位+その他)
    - 複数の部位の対応付け、リンクペア問題 (例：画像中の二人分の部位を、どうやって人ごとに分けるか)
        - top-downアプローチ：物体検出で人物切り出し
            - 欠点1. 計算量が人数に比例して肥大化
            - 欠点2. 姿勢推定精度が物体検出精度に依存
        - bottom-upアプローチ：直接部位を対応付ける(OpenPoseのPAFs)
- PAFs (Part Affinity Fields) の概念を理解する
    - 全人物の全部位を特定
    - ピクセルごとに、37リンク(例：左肘-左手首)に該当する確率を回帰する
- OpenPoseによる姿勢推定の3 stepの流れを理解する
    1. 前処理：368x368にリサイズ、色情報の標準化
    1. 推論：画像→ピクセルごと部位確信度(19x368x368), ピクセルごとリンク確信度(PAF, 38x368x368)
    1. 後処理：部位座標の決定(1ピクセル)、リンクの決定(部位座標とPAFから導出)、リサイズ

## 4.2 DatasetとDataLoaderの実装

- マスクデータについて理解する
    - 姿勢推定モデルの性能劣化を防ぐため、アノテーションが存在しない人物を黒く塗りつぶす
- OpenPoseで使用するDataset、DataLoaderを実装できるようになる
    - 省略
- OpenPoseの前処理およびデータオーギュメンテーションで何をしているか理解する
    - 前処理
        - アノテーション辞書を作成し、首座標((右肩+左肩)/2)を追加
            - 検出部位を増やして、推定精度を高めるため
    - オーギュメンテーション
        - 画像処理
            - 拡大・縮小、回転、切り出し、反転
        - アノテーション辞書の修正
            - 画像処理によりはみ出た部位について、アノテーションの視認性情報を修正する
    - 色情報の標準化
    - アノテーション画像の作成
        - 部位アノテーション画像 - heatmapsの作成 (サイズ:46x46, Featuresモジュールに合わせる)
            - 正解範囲が不当に小さい(1px)ため、ガウス分布で周辺ピクセルの確率を設定する
        - リンクアノテーション画像 - PAFsの作成 (サイズ:46x46, 同上)
            - 部位間の直線上のピクセルを1とする

## 4.3 OpenPoseのネットワーク構成と実装

- OpenPoseのネットワーク構造をモジュール単位で理解する
    - 概要：Feature + Stage x 6 (heatmaps, pafを出力)
    - Feature
        - 入力：画像(3 x 368 x 368)
        - 出力：特徴量(128 x 46 x 46)
    - Stage
        - PAFs用のサブネットワーク(Block<stage_id>_1)とheatmapsのサブネットワーク(Block<stage_id>_2)
        - 入力：特徴量(128 x 46 x 46) + 前Stageの出力(PAF:38 x 46 x 46, heatmaps:19 x 46 x 46)
        - 出力：PAFs (38 x 46 x 46), heatmaps (19 x 46 x 46)
- OpenPoseのネットワーククラスを実装できるようになる
    - 順伝播
        - 出力の計算：ネットワーク構成通り
        - 学習用の値保存：各StageのPAFs, heatmapsについて学習させるため、各Stageの出力を保存する

## 4.4 Feature、Stageモジュールの解説と実装

- Featureモジュールのサブネットワーク構成を理解する
    - VGG-19の畳み込み層10個分 + (C3+R) x 2
- Stageモジュールのblockを構成するサブネットワークを理解する
    - ブロックごとに同じ構成。最終層のみブロックの出力数に依存して決定
    - Stage1
        (C3+R) x 3 + (C1+R) x 1 + C1
    - Stage2-6
        (C7+R) x 5 + (C1+R) x 1 + C1

## 4.5 TensorBoardXを使用したネットワークの可視化手法

- 省略

## 4.6 OpenPoseの学習

- OpenPoseの学習を実装できるようになる
    - 損失関数の定義
        - PAFs, heatmapsそれぞれで、ピクセルごとに回帰問題として損失関数を定義(最小二乗誤差)
        - 各Stageの誤差を計算し、ネットワークモデル全体の誤差は加算して求める
        - マスク部分(人が映っているが、姿勢情報がない)については、損失を計算しない

## 4.7 OpenPoseの推論

- OpenPoseの学習済みモデルをロードできるようになる
    - ネットワークの構成は同じだが、レイヤの名前が違う場合の学習済み重みの読み込み
        - レイヤの名前を変えたstate_dictを用意する
- OpenPoseの推論を実装できるようになる
    - heatmapsとPAFsからリンクを求めて画像に上書きする(decode_pose)
        - heatmapsから部位の特定
            - 周囲と比較して最大かつ一定の閾値より大きな値を持つピクセルを部位とする
        - PAFsからリンクの特定
            - 各リンク(例：左肘、左手首)について、PAF値を求める
                1. 算出対象領域を、左肘と左手首を頂点とする長方形とする
                1. 長方形内で、リンク候補直線を複数用意する
                1. リンク候補直線上のPAFsの合計値に対して、左肘-左手首間の直線の傾きからのずれを重みづけして加算した値をPAF値とする
            - PAF値最大のリンクを正しいリンクとする
            - 誤って二人以上の人間を混ぜた場合(グラフ内に首が二つある場合)は適切に分割する

## まとめ(OpenPose最新版との違い)

- 精度と処理速度の向上：ネットワークの形、カーネルサイズを変更
    - heatmapsよりPAFsを正確に推定するネットワークに変更
- 身体部位の追加：足先
- PAFsの追加：37より多いPAFsへ。
