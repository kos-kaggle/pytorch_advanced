# 9 動画分類（3DCNN, ECO）

## 9-1 動画データに対するディープラーニングとECOの概要
1. 動画データをディープラーニングで扱う際の注意点と対策について理解する
    - 静止画の空間方向のゆらぎを畳み込み層で処理したように、動画では時間方向のゆらぎを吸収する２通りの方法が提案されてきた
        1. C3D(Convolutional 3D):
            高さ・幅・時間の３次元フィルタで畳み込み
        2. Two-Stream ConvNets:
            畳み込みはせず、オプティカルフロー（動画を静止画に分割した時に、連続する２枚のフレームで物体が移動した軌跡をベクトルで示した画像）を利用
    - C3Dは時間方向の特徴量をデータから学習させるため、大量の動画データと学習・推論時間が必要という欠点がある。
        → ECOモデルで解決

2. ECO(Efficient Convolutional Network for Online Video Understanding)のモデルの概要を理解する
    - フレーム画像を2次元の畳み込みNNで小さなサイズの特徴量に変換 → それらをC3Dに入力するモデル
    1. 前処理（動画をフレームごとの画像に分解、リサイズ、色情報の標準化）
       全フレームは枚数が多いので、等間隔に取り出した複数枚の画像だけ利用する（例：10秒の動画なら16フレームほど）
    2. 2D Netモジュール（画像処理モデル：inception-v2）に各フレームを入力
    3. 出力テンソルを結合させ、これを3D Netモジュールに入力
    4. 全結合層でクラス分類し、ソフトマックス関数で確率変換

## 9-2 2D Netモジュール（Inception-v2）の実装
1. ECOの2D Netモジュールの概要を理解する
    - ４つのモジュールで構成 (図9.2.1)
        - BasicConv (図9.2.2):
            - 基本的な畳み込みニューラルネットによる特徴量変換
            - ２次元畳み込み、バッチノーマライゼーション、ReLU、マックスプーリング
        - InceptionA ~ InceptionC (図9.2.3 ~ 9.2.5):
            - フィルタサイズの小さな畳み込み層を並列に実行（フィルタサイズの大きな畳み込みを行うよりも学習パラメータ数が少ない）
            - 1×1や3×3のConvolutionsで構成
            - InceptionCのみ並列なし

2. Inception-v2を実装できるようになる

## 9-3 3D Netモジュール(3DCNN)の実装
1. ECOの3D Netモジュールの概要を理解する
    - 3次元の畳み込みで構成されたResNetで特徴変換（Resnet_3D_3, Resnet_3D_4, Resnet_3D_5）
    - 全結合の代わりに入力と同じサイズのAverage Poolingを使用（パラメータ増大を避けるため）
2. 3D Resnetを実装できるようになる
    - Resnet_3D_3（図9.3.2）:
        3次元畳み込み → residual側と２回の畳み込み層側に分岐 → 加算してバッチノーマライゼーション＆ReLU
    - Resnet_3D_4（図9.3.3）:
        residual側と２回の畳み込み層側に分岐 → 加算 → residual側と２回の畳み込み層側に分岐 → 加算してバッチノーマライゼーション＆ReLU 
    - Resnet_3D_5（図9.3.4）:
        レイヤー構成はResnet_3D_4と同じ（チャネル数が異なる）

## 9-4 Kinetics動画データセットをDataLoaderに実装
1. Kinetics動画データセットをダウンロードできるようになる
    - 人物の動作データ（１動画10秒程度、400もしくは600クラス、各クラス500本の動画）

2. 動画データをフレームごとの画像データに変換できるようになる

3. ECOで使用するためのDataLoaderを実装できるようになる
    - これまでのDataLoader作成手順と同じだが、動画データを分割した画像データを扱うため、複数枚の画像をセットにして取り扱う
    1. 画像のサイズを短い変の長さ224になるようリサイズ
    2. 画像の中心から224×224の範囲を切り出す（センタークロップ）
    3. データをPytorchのテンソルに変換
    4. データを標準化
    5. frame数分の画像を1つのテンソルにまとめる

## 9-5 ECOモデルの実装と動画分類の推論実施
1. ECOモデルを実装できる
    - 入力テンソルは5次元（batch_num, frames, チャネル, 高さ, 幅）だが、PyTorchのnn.Conv2Dクラスは4次元テンソルしか入力できない
    → ミニバッチ数とframesを掛けて無理やり4次元化
    - 2D Netモジュールの出力を3D Netモジュールに入力するため、batch_num×framesに変形した部分を元に戻して5次元にする
2. 学習済みのECOモデルを自分のモデルにロードできる
    - ECO著者の学習済みモデルがGitHubに公開
3. ECOモデルを使用して、テストデータの推論ができる